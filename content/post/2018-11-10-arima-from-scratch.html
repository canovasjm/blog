---
title: ARIMA from scratch
author: Juan M. Canovas
date: '2018-12-31'
slug: arima-from-scratch
categories: []
tags: []
output:
  blogdown::html_page:
    number_sections: true
    toc: true
---


<div id="TOC">
<ul>
<li><a href="#introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="#the-data"><span class="toc-section-number">2</span> The data</a><ul>
<li><a href="#first-analysis-time-plot"><span class="toc-section-number">2.1</span> First analysis: time plot</a></li>
</ul></li>
<li><a href="#transformations"><span class="toc-section-number">3</span> Transformations</a><ul>
<li><a href="#variance-stabilization-transformation"><span class="toc-section-number">3.1</span> Variance stabilization transformation</a></li>
<li><a href="#trend-removal"><span class="toc-section-number">3.2</span> Trend removal</a><ul>
<li><a href="#non-seasonal-differentiation"><span class="toc-section-number">3.2.1</span> Non-seasonal differentiation</a></li>
<li><a href="#seasonal-differentiation"><span class="toc-section-number">3.2.2</span> Seasonal differentiation</a></li>
</ul></li>
<li><a href="#stationary-data"><span class="toc-section-number">3.3</span> Stationary data</a></li>
</ul></li>
<li><a href="#model-fitting-and-cross-validation"><span class="toc-section-number">4</span> Model fitting and cross-validation</a><ul>
<li><a href="#model-selection"><span class="toc-section-number">4.1</span> Model selection</a></li>
</ul></li>
<li><a href="#forecast"><span class="toc-section-number">5</span> Forecast</a></li>
<li><a href="#more-plots-original-data-forecast"><span class="toc-section-number">6</span> More plots: Original data + forecast</a></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>Hi there! This post is a modification of the final project I did for my Time Series class and the idea is simple: fit an ARIMA model and make a forecast. To do so in R we can use <code>auto.arima()</code> function from {forecast} package or we can decide what model are we going to fit and why. We will choose the latter path :)</p>
<p>Here we are going to explore how the number of domestic air passengers in Argentina has evolved in the last years, fit a model to the data, and forecast the number of domestic passengers for the next twelve months.</p>
<hr />
<p>Before starting we will load all the libraries needed:</p>
<pre class="r"><code># required libraries  
library(dplyr)
library(astsa)
library(knitr)</code></pre>
</div>
<div id="the-data" class="section level1">
<h1><span class="header-section-number">2</span> The data</h1>
<p>The data was taken from <strong>“Tablas de Movimientos y Pasajeros EANA 2014 - 2018”</strong>, a report from Empresa Argentina de Navegacion Aerea. It can be accessed via the following link: <a href="https://www.eana.com.ar/estadisticas#informes" class="uri">https://www.eana.com.ar/estadisticas#informes</a></p>
<p><strong>NOTE: The curious reader will note that the data file available now on EANA’s website is different from the one I will work with. When I started this project, the data file available was <a href="https://drive.google.com/open?id=1fm7KckXnKaHfu_RZ7FMVVC0hNJs6QD_q">this</a>. At some point between August 2018 and December 2018 they changed the file including more years and modifying the numbers.</strong></p>
<p>The data set I used for my project contains a lot of information about airline passengers and flights in Argentina for the period 2014 - 2018. We will concentrate on the number of domestic airline passengers for the 54 months between January 2014 and June 2018.</p>
<p>The data is presented as an xlsx file and it is displayed in a way that it is hard to import in R. Hence, before importing it, I pre-cleaned it using Microsoft Excel. You can access the pre-cleaned version <a href="https://drive.google.com/open?id=1ZV8cLn3RglLMw79KNUUj75mZ68axwhBY">here</a>.</p>
<pre class="r"><code># import csv file
df &lt;- read.csv(&quot;/home/jm/blog/static/passengers_ts.csv&quot;, 
               header = TRUE)

# remove year and month
dat &lt;- df %&gt;% 
  select(-c(year, month))

# create time series object
dat &lt;- dat %&gt;% 
  ts(start = c(2014, 1), end = c(2018, 6), deltat = 1/12)</code></pre>
<div id="first-analysis-time-plot" class="section level2">
<h2><span class="header-section-number">2.1</span> First analysis: time plot</h2>
<p>The first step in the analysis is to make a plot of the original data, where the number of domestic passengers is taken as the response variable and the time (months) as the explanatory variable. To do the plot we just use the function <code>plot.ts()</code></p>
<pre class="r"><code># original data time plot
plot.ts(dat[ , 1],
        ylab = &quot;thousand passengers&quot;,
        main = &quot;Domestic air passengers in Argentina 2014 - 2018&quot;)</code></pre>
<p><img src="/post/2018-11-10-arima-from-scratch_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>The time plot above is showing that the data presents an upward trend and the variability is not constant over time. Because of these two facts, we can claim that the weak stationarity conditions are not met and, additionally, it seems that there is a seasonal behaviour of the underlying process.</p>
<p>Before fitting a model we will need to do some work on this data: i) variance stabilization transformation and ii) trend removal.</p>
</div>
</div>
<div id="transformations" class="section level1">
<h1><span class="header-section-number">3</span> Transformations</h1>
<div id="variance-stabilization-transformation" class="section level2">
<h2><span class="header-section-number">3.1</span> Variance stabilization transformation</h2>
<p><em>Why do we want to stabilize the variance?</em>, you may be wondering. Well, the problem with non-constant variance (a.k.a <em>heteroscedasticity</em>) is that, as time grows, small percent changes become large absolute changes. And we don’t want that in our model.</p>
<p>So, in order to stabilize the variance, we took the natural logarithm of the original data and will store the transformed data in <strong>log_dat</strong></p>
<pre class="r"><code># log transformation
log_dat &lt;- log(dat[ , 1])
plot.ts(log_dat,
        ylab = &quot;log thousand passengers&quot;,
        main = &quot;Domestic air passengers in Argentina 2014 - 2018&quot;)</code></pre>
<p><img src="/post/2018-11-10-arima-from-scratch_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>This plot looks very similar to the first, but the range of the dependent variable is considerably smaller (pay attention to the values on the y-axis).</p>
</div>
<div id="trend-removal" class="section level2">
<h2><span class="header-section-number">3.2</span> Trend removal</h2>
<p>On the first time plot we observed an upward trend that can be removed by differencing the data. Besides the time plot, one can use the ACF to determine if differencing is needed before fitting a model.<br />
In this section, we will use the <code>acf2()</code> function from {astsa} package, which plots the ACF and PACF values for different lags.</p>
<p><em>Note: In the x-axis for the ACF and PACF plots below, the integer numbers represent years. In between two integers there are twelve marks in the x-axis, one for each month of the year.</em></p>
<pre class="r"><code># correlation structure
log_acf &lt;- acf2(log_dat, 
                max.lag = 30, 
                main = &quot;log thousand passengers&quot;)</code></pre>
<p><img src="/post/2018-11-10-arima-from-scratch_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>As we see in the ACF plot above, it presents a slow decay as the lag increases. This supports our initial hypothesis that difference is needed.</p>
<div id="non-seasonal-differentiation" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Non-seasonal differentiation</h3>
<p>Here we will difference the transformed data (<strong>log_dat</strong>) and repeat the ACF and PACF analysis using <code>acf2()</code>.</p>
<pre class="r"><code># differentiation
dlog_dat &lt;- diff(log_dat, lag = 1)
dlog_acf &lt;- acf2(dlog_dat,
                  max.lag = 45,
                  main = &quot;(Non seasonal) differenced log thousand passengers&quot;)</code></pre>
<p><img src="/post/2018-11-10-arima-from-scratch_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Beautiful, isn’t it? Be careful though, non-seasonal differencing removes only one part of the correlation. In the ACF plot above we still observe seasonal correlation for <span class="math inline">\(12 * k\)</span> for <span class="math inline">\(k = 1, 2, \ldots\)</span>.</p>
<p>In plain English, this is telling us that the number of air passengers of a certain month is related to the number of passengers for the same month in previous years. That is, the number of passengers in January 2018 is related to the number of passengers in January 2017, and so on.</p>
<p>Since the ACF tails off for <span class="math inline">\(12 * k\)</span> for <span class="math inline">\(k = 1, 2, \ldots\)</span> and PACF cuts off after lag 1, a seasonal autoregressive component of order one is needed.</p>
<p>Additionally, the following time plot of the non-seasonal differenced log data also helps in the analysis: we observe how the peaks and valleys repeat every twelve months.</p>
<pre class="r"><code># time plot of non seasonal differenced data
plot.ts(dlog_dat,
        ylab = &quot;log thousand passengers&quot;,
        main = &quot;(Non seasonal differenced) log thousand passengers&quot;)
abline(h = 0, lwd = 1.5)</code></pre>
<p><img src="/post/2018-11-10-arima-from-scratch_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="seasonal-differentiation" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Seasonal differentiation</h3>
<p>Now we will remove the seasonal correlation. To do this we use again the function <code>diff()</code>. Note that this time <code>lag = 12</code>: we are telling R to difference observations that are 12 months apart. This will perform:</p>
<ul>
<li>January 2018 - January 2017<br />
</li>
<li>February 2018 - February 2017<br />
</li>
<li>March 2018 - March 2017</li>
</ul>
<p>So on and so forth. Once we took seasonal differentiation, the ACF values lie between the blue dashed lines; meaning that the autocorrelation function is not significantly different from zero.</p>
<pre class="r"><code># seasonal and non seasonal differenced log data - ACF/PACF
ddlog_dat &lt;- diff(dlog_dat, lag = 12)
ddlog_acf &lt;- acf2(ddlog_dat,
                   max.lag = 35,
                   main = &quot;(Seasonal and non seasonal) differenced log thousand passengers&quot;)</code></pre>
<p><img src="/post/2018-11-10-arima-from-scratch_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
</div>
<div id="stationary-data" class="section level2">
<h2><span class="header-section-number">3.3</span> Stationary data</h2>
<p>Finally, we make a time plot of the transformed and differenced data and it shows that now the process seems to be stationary:</p>
<pre class="r"><code># seasonal and non seasonal differenced log data - time plot
plot.ts(ddlog_dat,
        type = &quot;l&quot;,
        ylab = &quot;log thousand passengers&quot;,
        main = &quot;(Seasonal and non seasonal) differenced log thousand passengers&quot;)
abline(h = 0, lwd = 1.5)</code></pre>
<p><img src="/post/2018-11-10-arima-from-scratch_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<hr />
</div>
</div>
<div id="model-fitting-and-cross-validation" class="section level1">
<h1><span class="header-section-number">4</span> Model fitting and cross-validation</h1>
<p>Now that we have analyzed our data, and decided which transformations we are going to apply, we are going to select the model with cross-validation (CV). However, the cross-validation procedure that we are going to apply with time series data is a little bit different to what we usually do with independent data. If you want to read about CV for time series I recommend <a href="https://stats.stackexchange.com/a/326247/218995">here</a>, <a href="https://robjhyndman.com/publications/cv-time-series/">here</a>, and <a href="https://robjhyndman.com/hyndsight/tscv/">here</a>.</p>
<p><em>Why do we need cross-validation?</em>. The answer is that we don’t want to test our models with the same data used to train them; that would be an overly optimistic scenario. Instead, we want to test our model on unseen data.</p>
<p>A graphic representation of this process is shown in <a href="https://robjhyndman.com/hyndsight/tscv/">Rob J Hyndman’s blog post</a> (I reproduced the plot below) and he also provides the code to make it <a href="https://gist.github.com/robjhyndman/9fa152c585442bb076eb42a30a020091">here</a>.</p>
<p>Starting with 36 of our 54 months we are going to:</p>
<ol style="list-style-type: decimal">
<li>Fit a model on a train set (blue dots),</li>
<li>Make a prediction for the test set (red dot),</li>
<li>Compute the error and square it,</li>
<li>Increase training data by one and repeat the process.</li>
</ol>
<p>(If we try to start with less than 36 months, the <code>arima()</code> function returns an error). Finally, we are going to average all the squared errors getting what is known as <em>Mean Squared Error (MSE)</em>.</p>
<p><img src="/post/2018-11-10-arima-from-scratch_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Using the analysis of the previous sections and the CV validation procedure explained above, here we will fit two models to the log-transformed data using the function <code>arima()</code>. The objective of fitting two models is to identify whether or not a moving average component is needed. This is not really clear in the ACF/PACF and time plots analysis we made before, so we will fit one model with q = 1 and one with q = 0 and then compare the MSE values from CV.</p>
<p>The models we are going to fit are:</p>
<p><strong>model_1</strong>: ARIMA(p = 1, d = 1, q = 1, P = 1, D = 1, Q = 0, S = 12)<br />
<strong>model_2</strong>: ARIMA(p = 1, d = 1, q = 0, P = 1, D = 1, Q = 0, S = 12)</p>
<pre class="r"><code>################################################################################
# CV for model 1
################################################################################
i &lt;- 36
MSE1 &lt;- c()

while(i &lt; length(log_dat)){
  # train the model with i observations
  m1 &lt;- arima(log_dat[1:i], 
              order = c(1, 1, 1), 
              seasonal = list(order = c(1, 1, 0), period = 12),
              method = &quot;ML&quot;)
  # predict observation i + 1
  y_hat &lt;- predict(m1, n.ahead = 1)
  # prediction MSE
  MSE1 &lt;- c(MSE1, (log_dat[i + 1] - y_hat$pred)^2)
  # increase i 
  i &lt;- i + 1
}

# untransform data: back to the original scale
exp(mean(MSE1))</code></pre>
<pre><code>## [1] 1.001494</code></pre>
<pre class="r"><code>################################################################################
# CV for model 2
################################################################################
i &lt;- 36
MSE2 &lt;- c()

while(i &lt; length(log_dat)){
  # train the model with i observations
  m2 &lt;- arima(log_dat[1:i], 
              order = c(1, 1, 0), 
              seasonal = list(order = c(1, 1, 0), period = 12),
              method = &quot;ML&quot;)
  # predict observation i + 1
  y_hat &lt;- predict(m2, n.ahead = 1)
  # prediction MSE
  MSE2 &lt;- c(MSE2, (log_dat[i + 1] - y_hat$pred)^2)
  # increase i
  i &lt;- i + 1
}

# untransform data: back to the original scale
exp(mean(MSE2))</code></pre>
<pre><code>## [1] 1.001469</code></pre>
<p>The MSE obtained with CV is slightly better for model 2. (We look for smaller values of MSE).</p>
<p>Now we are going to use the function <code>sarima()</code> from package {astsa}. This function is basically a wrapper of <code>arima()</code>, but additionally it returns an object called <strong>ttable</strong> that has the results of t-tests performed on each of the coefficients. The <strong>ttable</strong> is also printed in the summary of the model. Using <code>sarima()</code> from {astsa} package:</p>
<p><strong>Model 1</strong></p>
<pre class="r"><code># model_1 fitting
m11 &lt;- sarima(log_dat, 
              p = 1, d = 1, q = 1, 
              P = 1, D = 1, Q = 0, S = 12, 
              details = FALSE)
m11</code></pre>
<pre><code>## $fit
## 
## Call:
## stats::arima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, 
##     Q), period = S), include.mean = !no.constant, transform.pars = trans, fixed = fixed, 
##     optim.control = list(trace = trc, REPORT = 1, reltol = tol))
## 
## Coefficients:
##          ar1      ma1     sar1
##       0.7151  -1.0000  -0.3902
## s.e.  0.1192   0.0872   0.1470
## 
## sigma^2 estimated as 0.001388:  log likelihood = 74.45,  aic = -140.91
## 
## $degrees_of_freedom
## [1] 38
## 
## $ttable
##      Estimate     SE  t.value p.value
## ar1    0.7151 0.1192   6.0006  0.0000
## ma1   -1.0000 0.0872 -11.4716  0.0000
## sar1  -0.3902 0.1470  -2.6545  0.0115
## 
## $AIC
## [1] -2.709764
## 
## $AICc
## [1] -2.700149
## 
## $BIC
## [1] -2.577951</code></pre>
<p><strong>Model 2</strong></p>
<pre class="r"><code># model_2 fitting
m22 &lt;- sarima(log_dat, 
              p = 1, d = 1, q = 0, 
              P = 1, D = 1, Q = 0, S = 12,
              details = FALSE)
m22</code></pre>
<pre><code>## $fit
## 
## Call:
## stats::arima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, 
##     Q), period = S), include.mean = !no.constant, transform.pars = trans, fixed = fixed, 
##     optim.control = list(trace = trc, REPORT = 1, reltol = tol))
## 
## Coefficients:
##          ar1     sar1
##       0.0898  -0.4209
## s.e.  0.1583   0.1548
## 
## sigma^2 estimated as 0.001608:  log likelihood = 72.53,  aic = -139.05
## 
## $degrees_of_freedom
## [1] 39
## 
## $ttable
##      Estimate     SE t.value p.value
## ar1    0.0898 0.1583  0.5671  0.5739
## sar1  -0.4209 0.1548 -2.7194  0.0097
## 
## $AIC
## [1] -2.674133
## 
## $AICc
## [1] -2.669423
## 
## $BIC
## [1] -2.575273</code></pre>
<div id="model-selection" class="section level2">
<h2><span class="header-section-number">4.1</span> Model selection</h2>
<p>From the tables above, we can see that the estimates of the coefficients for model 1 are all significantly different from zero; while this is not the case for model 2. In the latter, the p-value for the non seasonal autoregressive coefficient estimate is 0.57 meaning that we fail to reject the null the hypothesis that the coefficient is equal to zero.</p>
<p>Additionally, AICc and BIC values are smaller for model 1, which leads us to prefer model 1 over model 2. There is one step left to conclude if the model is adequate or not: residual analysis. For this analysis I used the following plots:</p>
<pre class="r"><code># residual plot for model 1
plot.ts(m1$residuals,
        ylab = &quot;log thousand passengers&quot;,
        main = &quot;Model 1 residuals&quot;)
abline(h = 0, lwd = 1.5)</code></pre>
<p><img src="/post/2018-11-10-arima-from-scratch_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<pre class="r"><code># ACF/PACF for model 1 residuals
res_acf &lt;- acf2(m1$residuals,
                max.lag = 30,
                main = &quot;ACF for model 1 residuals&quot;)</code></pre>
<p><img src="/post/2018-11-10-arima-from-scratch_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>In the time plot of the residuals for model 1, they seem to be uncorrelated. Furthermore, the ACF/PACF values are not significantly different from zero; except for the PACF values corresponding to lag three, nine, and twelve. This result suggests the possibility that there is still some slight seasonal regularity in the residuals, but the addition of another seasonal autoregressive component does not improve the results.</p>
<p>To wrap up, the selected model is model 1:</p>
<pre class="r"><code># coefficients estimates
m1$coef</code></pre>
<pre><code>##        ar1        ma1       sar1 
## -0.1251408  0.2365606 -0.4286284</code></pre>
<pre class="r"><code># coefficients&#39; standard error
sqrt(diag(m1$var.coef))</code></pre>
<pre><code>##       ar1       ma1      sar1 
## 0.5888534 0.5596424 0.1568349</code></pre>
</div>
</div>
<div id="forecast" class="section level1">
<h1><span class="header-section-number">5</span> Forecast</h1>
<p>For the forecast we can use <code>sarima.for()</code> from package {astsa}, but it automatically prints a plot of the forecasted values.<br />
I wanted to show how to do the plots instead, so we are going to use the <code>predict()</code> function to get the forecast. However, the <strong>m11</strong> object we fitted with <code>sarima()</code> function is not going to work here, so in order to use the <code>predict()</code> function we are going to use the <strong>m1</strong> model that we created with <code>arima()</code> function.</p>
<p>Note that the arguments of <code>predict()</code> are the name of the model and the forecast scope. Since our data is monthly, we will set <code>n.ahead = 12</code> to predict a whole year.</p>
<pre class="r"><code># fit the m1 model with all the observations available
m1 &lt;- arima(log_dat, 
            order = c(1, 1, 1), 
            seasonal = list(order = c(1, 1, 0), period = 12),
            method = &quot;ML&quot;)</code></pre>
<p>Forecast for the next year using <code>predict()</code> and model <strong>m1</strong>:</p>
<pre class="r"><code># forecast
m1_for &lt;- predict(m1, n.ahead = 12)</code></pre>
</div>
<div id="more-plots-original-data-forecast" class="section level1">
<h1><span class="header-section-number">6</span> More plots: Original data + forecast</h1>
<p>Finally, we are going to plot the original data and our forecast. To do so we start by creating a data frame with the values of interest.</p>
<pre class="r"><code># final values
f_values &lt;- data.frame(&quot;Year&quot; = c(rep(2017, 6), rep(2018, 6)), 
                       &quot;Month&quot; = c(&quot;Jul&quot;, &quot;Aug&quot;, &quot;Sep&quot;, &quot;Oct&quot;, &quot;Nov&quot;, &quot;Dec&quot;,
                                   &quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;, &quot;Jun&quot;),
                       &quot;Forecasted_Passengers&quot; = round(exp(m1_for$pred), 2))

## forecast plots 
# past data
t &lt;- 1:66

plot(t, rep(NA, 66), 
     ylim = c(600, 1500),
     xlab = &quot;t [months]&quot;,
     ylab = &quot;thousand passengers&quot;,
     main = &quot;Train data and forecaseted passengers&quot;)

grid(lty = 1, col = gray(0.9))

lines(t, 
      c(df[1:54, 3], rep(NA, 12)),
      lwd = 2,
      type = &quot;l&quot;)

# add forecasted values
lines(t, c(rep(NA, 53), df[54, 3], f_values$Forecasted_Passengers),
      lwd = 2,
      col = &quot;red&quot;)

# legend
legend(x = &quot;bottomright&quot;, 
       legend = c(&quot;Train&quot;, &quot;Forecast&quot;),
       col = c(1, 2), 
       pch = c(16, 16),
       bty = &quot;n&quot;)</code></pre>
<p><img src="/post/2018-11-10-arima-from-scratch_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>Since the data taken to run the forecast was the log-transformed data, it is required to untransform the data to present the results. Such values are displayed in the next table:</p>
<table>
<thead>
<tr class="header">
<th align="left">Year</th>
<th align="left">Month</th>
<th align="left">log_Air_Passengers</th>
<th align="left">Air_Passengers</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">2018</td>
<td align="left">Jul</td>
<td align="left">7.19</td>
<td align="left">1325.93</td>
</tr>
<tr class="even">
<td align="left">2018</td>
<td align="left">Aug</td>
<td align="left">7.18</td>
<td align="left">1307.09</td>
</tr>
<tr class="odd">
<td align="left">2018</td>
<td align="left">Sep</td>
<td align="left">7.16</td>
<td align="left">1283.27</td>
</tr>
<tr class="even">
<td align="left">2018</td>
<td align="left">Oct</td>
<td align="left">7.20</td>
<td align="left">1340.69</td>
</tr>
<tr class="odd">
<td align="left">2018</td>
<td align="left">Nov</td>
<td align="left">7.20</td>
<td align="left">1338.72</td>
</tr>
<tr class="even">
<td align="left">2018</td>
<td align="left">Dec</td>
<td align="left">7.18</td>
<td align="left">1319.26</td>
</tr>
<tr class="odd">
<td align="left">2019</td>
<td align="left">Jan</td>
<td align="left">7.25</td>
<td align="left">1409.66</td>
</tr>
<tr class="even">
<td align="left">2019</td>
<td align="left">Feb</td>
<td align="left">7.15</td>
<td align="left">1269.25</td>
</tr>
<tr class="odd">
<td align="left">2019</td>
<td align="left">Mar</td>
<td align="left">7.20</td>
<td align="left">1339.67</td>
</tr>
<tr class="even">
<td align="left">2019</td>
<td align="left">Apr</td>
<td align="left">7.09</td>
<td align="left">1197.56</td>
</tr>
<tr class="odd">
<td align="left">2019</td>
<td align="left">May</td>
<td align="left">7.06</td>
<td align="left">1165.04</td>
</tr>
<tr class="even">
<td align="left">2019</td>
<td align="left">Jun</td>
<td align="left">7.01</td>
<td align="left">1112.37</td>
</tr>
</tbody>
</table>
<p><em>Note: The unit of passengers in the original data set is thousands, so the number 1000 in the table corresponds to 1000000 passengers.</em></p>
</div>
